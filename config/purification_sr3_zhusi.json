{
    "name": "purification_sr3", // experiments name
    "gpu_ids": [0], // gpu ids list, default is single 0
    "seed" : 42, // random seed, seed <0 represents randomization not used
    "finetune_norm": false, // find the parameters to optimize

    "path": { //set every part file path
        "base_dir": "experiments", // base path for all log except resume_state
        "code": "code", // code backup
        "tb_logger": "tb_logger", // path of tensorboard logger
        "results": "results",
        "checkpoint": "checkpoint",
        "resume_state": "null"
        //experiments/train_purification_sr3_230613_223001/checkpoint/best
//        mnist test experiments/train_inpainting_places2_230416_153558/checkpoint/645
        //experiments/train_purification_sr3_230520_002747/checkpoint/227
//        experiments/train_purification_sr3_230503_212523/checkpoint/1001 cifar10
        // experiments/train_inpainting_places2_230317_141555/checkpoint/5 imagenet
        // "resume_state": null // ex: 100, loading .state  and .pth from given epoch and iteration
    },

    "datasets": { // train or test
        "train": {
            "which_dataset": {  // import designated dataset using arguments
                "name": ["data.dataset", "InpaintDataset3"], // import Dataset() class / function(not recommend) from data.dataset.py (default is [data.dataset.py])
                "args":{ // arguments to initialize dataset
                    "data_root": "../Adv_img/cifar10/train/train",   // ../Adv_img/cifar10/train/train
                    "data_len": -1,
                    "img_opt": "other",  //  compression mix
                    "mode": "train",
                    "mask_config": {
                        "mask_mode": "noise"
                    }
                }
            },
            "dataloader":{
                "validation_split": 1024 , // percent or number 2
                "args":{ // arguments to initialize train_dataloader
                    "batch_size": 64, // batch size in each gpu 3
                    "num_workers": 16,
                    "shuffle": true,
                    "pin_memory": true,
                    "drop_last": true
                },
                "val_args":{ // arguments to initialize valid_dataloader, will overwrite the parameters in train_dataloader
                    "batch_size": 5000, // batch size in each gpu
                    "num_workers": 16,
                    "shuffle": false,
                    "pin_memory": true,
                    "drop_last": false
                }
            }
        },
        "test": {
            "which_dataset": {
                "name": "InpaintDataset3", // import Dataset() class / function(not recommend) from default file
                "args":{
                    "data_root": "../Adv_img/cifar10/test/resnet50/pgd",    // data/ImageNet50/test  ../PyTorchProject/Attack/CIFAR10_data/fgsm/resnet50/0.1 ../Adv_img/cifar10/test/resnet50/pgd  ../CIFAR_data/test
                    "img_opt": "other",  //compression adv
                    "mode": "test",

                    "mask_config": {
                        "mask_mode": "noise"
                    }
                }
            },
            "dataloader":{
                "args":{
                    "batch_size": 5000,
                    "num_workers": 16,
                    "shuffle": false,
                    "pin_memory": true
                }
            }
        }
    },

    "model": { // networks/metrics/losses/optimizers/lr_schedulers is a list and model is a dict
        "which_model": { // import designated  model(trainer) using arguments
            "name": ["models.model", "Palette"], // import Model() class / function(not recommend) from models.model.py (default is [models.model.py])
            "args": {
                "sample_num": 8, // process of each image
                "task": "inpainting",
                "ema_scheduler": {
                    "ema_start": 1,
                    "ema_iter": 1,
                    "ema_decay": 0.9999
                },
                "optimizers": [
                       //5e-5  Adam
                    {
//                        "lr": 1e-4,
//                        "rho": 0.9,
//                        "eps": 1e-06,
//      			                  "weight_decay": 0
                        "lr": 3e-5, "weight_decay": 0
                    }
                ],
                "only_out":"out" ,// cat out count
                "data_type": "cifar10",
                "classifier": "resnet50",
                "classifier_path": "../Model_Weight/"
            }	
	        },
        "which_networks": [ // import designated list of networks using arguments
            {
                "name": ["models.network", "Network"], // import Network() class / function(not recommend) from default file (default is [models/network.py])
                "args": { // arguments to initialize network
                    "init_type": "kaiming", // method can be [normal | xavier| xavier_uniform | kaiming | orthogonal], default is kaiming
                    "module_name": "sr3", // sr3 | guided_diffusion
                    "unet": {
                        "in_channel": 6,
                        "out_channel": 3,
                        "inner_channel": 64,
                        "channel_mults": [ // 1224
                            1,
                            2,
                            2,
                            4
                        ],
                        "attn_res": [
                            // 32,
                            16
                            // 8
                        ],
//                        "num_head_channels": 32,  // sr need //
                        "res_blocks": 2	,
                        "dropout": 0.2,
                        "image_size": 32 //256
                    },
                    "beta_schedule": {
                        "train": {
                            "schedule": "linear", // cosine  linear warmup10
                            "n_timestep": 2000,  // 2000
                            // "n_timestep": 5, // debug
                            "linear_start": 1e-6,
                            "linear_end": 0.01
                        },
                        "test": {
                            "schedule": "linear",
                            "n_timestep": 50, // 1000
                            "linear_start": 1e-6, // 1e-4
                            "linear_end":0.01 // 0.09
                        }
                    }
                }
            }
        ],
        "which_losses": [ // import designated list of losses without arguments
            "control_loss" // import mse_loss() function/class from default file (default is [models/losses.py]), equivalent to { "name": "mse_loss", "args":{}}
        ],
        "which_metrics": [ // import designated list of metrics without arguments
            "mae" // import mae() function/class from default file (default is [models/metrics.py]), equivalent to { "name": "mae", "args":{}}
        ]
    },

    "train": { // arguments for basic training
        "n_epoch":35000, // max epochs, not limited now 1e8
        "n_iter": 1e10, // max interations
        "val_epoch": 100, // valdation every specified number of epochs
        "save_checkpoint_epoch": 10,
        "log_iter": 1e4, // log every specified number of iterations
        "tensorboard" : true // tensorboardX enable
    },

    "debug": { // arguments in debug mode, which will replace arguments in train
        "val_epoch": 1,
        "save_checkpoint_epoch": 1,
        "log_iter": 10,
        "debug_split": 50 // percent or number, change the size of dataloder to debug_split.
    }
}
